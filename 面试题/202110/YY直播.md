十五、YY直播

20211022 下午两点半
```text
一面：
1.为什么选用Hudi？
    传统数据解决方案中，常用Hive来构建T+1级别的数据仓库，通过HDFS存储实现海量数据的存储与水平扩容，通过Hive实现元数据的管理以及数据操作的SQL化。虽然能够在海量批处理场景中取得不错的效果，但依然存在如下现状问题：
    
    问题一：不支持事务
    由于传统大数据方案不支持事务，有可能会读到未写完成的数据，造成数据统计错误。为了规避该问题，通常控制读写任务顺序调用，在保证写任务完成后才能启动读任务。但并不是所有读任务都能够被调度系统约束住，在读取时仍存在该问题。
    
    问题二：数据更新效率低
    业务系统库的数据，除流水表类的数据都是新增数据外，还有很多状态类数据表需要更新操作（例如：账户余额表，客户状态表，设备状态表等），而传统大数据方案无法满足增量更新，常采用拉链方式，先进行join操作再进行insert overwrite操作，通过覆盖写的方式完成更新操作，该操作往往需要T+1的批处理模式 ，从而导致端到端数据时延T+1，存在效率低、成本高等问题。
    
    问题三：无法及时应对业务表变化
    上游业务系统对数据schema发生变更后，会导致数据无法入湖，需要数据湖的表schema进行同步调整。从技术实现上采用数据表重建的方式来满足该场景，导致数据湖的数据表的管理与维护方案复杂，实现成本高。另外该种场景通常需要业务部门与数据团队相配合，通过管理流程来实现表结构的同步。
    
    问题四：历史快照表数据冗余
    传统数据湖方案需要对历史的快照表进行存储，采用全量历史存储的方式实现，例如：天级历史快照表，每天都会全量存储全表数据。这样就造成了大量的数据存储冗余，占用大量的存储资源。
    
    问题五：小批量增量数据处理成本高
    传统数据湖为了实现增量ETL，通常将增量数据按照分区的方式进行存储，若为了实现T+0的数据处理，增量数据需要按照小时级或者分钟级的分区粒度。该种实现形式会导致小文件问题，大量分区也会导致元数据服务压力增大。

2.讲一下Hudi的布隆过滤器
    是Hudi为加快数据upsert采用的一种解决方案，即判断record是否已经在文件中存在，若存在，则更新，若不存在，则插入。对于upsert显然无法容忍出现误判，否则可能会出现应该插入和变成了更新的错误，那么Hudi是如何解决误判问题的呢？一种简单办法是当Bloom Filter判断该元素存在时，再去文件里二次确认该元素是否真的存在；
    而当Bloom Filter判断该元素不存在时，则无需读文件，通过二次确认的方法来规避Bloom Filter的误判问题，实际上这也是Hudi采取的方案，值得一提的是，现在Delta暂时还不支持Bloom Filter，其判断一条记录是否存在是直接通过一次全表join来实现，效率比较低下。
    
3.HBase为什么读写并发高且快的原理
    HBase实现高并发读写的关键在于其采用的多版本并发控制机制，以及其分布式存储和计算的优势。在HBase中，MVCC的实现原理如下：
        写操作：对于写操作，HBase在执行写操作时会为每个写操作分配一个写入号（write number），并将每个数据单元（cell）的写入号存储在内存中。写操作完成后，会声明该写入号已经完成。
        读操作：对于读操作，HBase首先为每个读操作分配一个读时间戳（read timestamp），然后根据这个时间戳来确定需要读取的数据版本。具体来说，读操作会返回小于或等于读时间戳的最大写入号对应的数据单元，从而实现多版本数据的并发读取。
        
4.Flink为什么选用rocksdb?
    先，RocksDB可以支持比内存更大的状态，因为它将工作状态首先写入到堆外/本地内存，然后在达到配置的阈值时刷新到本地磁盘。这意味着RocksDB可以支持比整个集群配置的堆容量更大的状态。其次，RocksDB不受JVM垃圾回收的影响，因此具有可预测的延迟。此外，RocksDB还支持增量检查点，这可以大大减少检查点时间。
    最后，RocksDB是唯一支持增量检查点的状态后端。因此，如果您的作业状态较大，需要增量检查点以减少检查点时间，或者需要更可预测的延迟而不受JVM垃圾回收的影响
    
5.kafka数据顺序性，如果不是kafka不是单主题单分区如何实现数据顺序性？
    这个可以根据业务数据的主键mod取模，将同主键的数据push到同一分区，这样就可以保证数据的顺序性
    
6.生产上Flink SQL任务怎么提交的？
7.Flink SQL转换成Flink任务的流程
8.Calcite解析SQL步骤
9.二叉树层级遍历
10.参与开源
```